{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I will try to store the content of the csv files in a HDFStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchesStore = pd.HDFStore('searchesNew.h5')\n",
    "bookingsStore = pd.HDFStore('bookings.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid combinate of [values_axes] on appending data [name->Date,cname->Date,dtype->string1336,shape->(1, 500000)] vs current table [name->Date,cname->Date,dtype->datetime64,shape->None]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-174062d338e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Files/searches.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'^'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TxnCode'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'OfficeID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Origin'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Destination'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RoundTrip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TxnCode'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'OfficeID'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Origin'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Destination'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RoundTrip'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msearchesStore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'searches'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_itemsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Time'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TxnCode'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'OfficeID'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Origin'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Destination'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RoundTrip'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, key, value, format, append, columns, dropna, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         self._write_to_group(key, value, append=append, dropna=dropna,\n\u001b[1;32m--> 914\u001b[1;33m                              **kwargs)\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m     def append_to_multiple(self, d, value, selector, data_columns=None,\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36m_write_to_group\u001b[1;34m(self, key, value, format, index, append, complib, encoding, **kwargs)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \u001b[1;31m# write the object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1273\u001b[1;33m         \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_table\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, obj, axes, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, **kwargs)\u001b[0m\n\u001b[0;32m   3576\u001b[0m         self.create_axes(axes=axes, obj=obj, validate=append,\n\u001b[0;32m   3577\u001b[0m                          \u001b[0mmin_itemsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_itemsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3578\u001b[1;33m                          **kwargs)\n\u001b[0m\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mcreate_axes\u001b[1;34m(self, axes, obj, validate, nan_rep, data_columns, min_itemsize, **kwargs)\u001b[0m\n\u001b[0;32m   3285\u001b[0m         \u001b[1;31m# validate the axes if we have an existing table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3286\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3287\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexisting_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   2786\u001b[0m                         raise ValueError(\n\u001b[0;32m   2787\u001b[0m                             \u001b[1;34m\"invalid combinate of [%s] on appending data [%s] \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2788\u001b[1;33m                             \"vs current table [%s]\" % (c, sax, oax))\n\u001b[0m\u001b[0;32m   2789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2790\u001b[0m                 \u001b[1;31m# should never get here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid combinate of [values_axes] on appending data [name->Date,cname->Date,dtype->string1336,shape->(1, 500000)] vs current table [name->Date,cname->Date,dtype->datetime64,shape->None]"
     ]
    }
   ],
   "source": [
    "for chunk in pd.read_csv('../Files/searches.csv', delimiter='^', chunksize=500000, usecols=['Date','Time','TxnCode','OfficeID','Country','Origin','Destination','RoundTrip'], dtype={'Date':np.str, 'Time':np.str, 'TxnCode': np.str, 'OfficeID': np.str,'Country': np.str, 'Origin': np.str,'Destination': np.str, 'RoundTrip': np.float64}):\n",
    "    searchesStore.append('searches',chunk,min_itemsize={'Date':10, 'Time':10,'TxnCode':3,'OfficeID':32,'Country':2,'Origin':3,'Destination':3,'RoundTrip':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.1 ms, sys: 27.6 ms, total: 108 ms\n",
      "Wall time: 712 ms\n"
     ]
    }
   ],
   "source": [
    "for chunk in pd.read_csv('../Files/bookingsClean.csv', delimiter='^', chunksize=500000, usecols=['act_date','dep_port','dep_city','arr_port','arr_city','pax'], parse_dates=['act_date'], dtype={'dep_port': object, 'dep_city': object, 'arr_city': object, 'arr_port': object, 'pax':np.float64}):\n",
    "    bookingsStore.append('bookings',chunk,min_itemsize={'act_date':20,'dep_port':3,'dep_city':15,'arr_port':3,'arr_city':15,'pax':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: searchesNew.h5\n",
       "/searches            frame_table  (typ->appendable,nrows->1000000,ncols->7,indexers->[index],dc->[Origin,Date_Time,RoundTrip,Country,Destination,TxnCode,OfficeID])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchesStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_Time      datetime64[ns]\n",
       "TxnCode                object\n",
       "OfficeID               object\n",
       "Country                object\n",
       "Origin                 object\n",
       "Destination            object\n",
       "RoundTrip             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchesStore.searches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: bookings.h5\n",
       "/bookings            frame_table  (typ->appendable,nrows->10000010,ncols->6,indexers->[index],dc->[arr_city,dep_city,pax,arr_port,act_date,dep_port])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookingsStore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
